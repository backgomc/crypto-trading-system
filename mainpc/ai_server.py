# íŒŒì¼ ê²½ë¡œ: mainpc/ai_server.py
# ì½”ë“œëª…: ë©”ì¸ PC AI Flask API ì„œë²„ (NASì™€ í†µì‹ ìš©)

import os
import sys
import json
import threading
import time
import logging
from pathlib import Path
from datetime import datetime
from flask import Flask, request, jsonify
from flask_cors import CORS
from typing import Dict, Optional, Callable

# ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent))

# AI ëª¨ë“ˆ ì„í¬íŠ¸
from nhbot_ai.data_collector import DataCollector
from nhbot_ai.model_trainer import ModelTrainer
from nhbot_ai.predictor import AIPredictor

# Flask ì•± ìƒì„±
app = Flask(__name__)
CORS(app, origins=['http://192.168.0.*', 'http://localhost:*'])  # NASì—ì„œ ì ‘ê·¼ í—ˆìš©

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/ai_server.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ============================================================================
# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬
# ============================================================================

class AIServerManager:
    """AI ì„œë²„ ë§¤ë‹ˆì € (ì‹±ê¸€í†¤)"""
    
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance
    
    def __init__(self):
        if self._initialized:
            return
            
        self.trainer = None
        self.predictor = None
        self.data_collector = DataCollector("BTCUSDT")
        self.training_thread = None
        self.training_status = {
            'status': 'idle',
            'start_time': None,
            'end_time': None,
            'current_epoch': 0,
            'total_epochs': 0,
            'accuracy': 0.0,
            'model_name': None,
            'error': None,
            'logs': []
        }
        
        # ëª¨ë¸ ë””ë ‰í† ë¦¬ ìƒì„±
        self.models_dir = Path("models")
        self.models_dir.mkdir(exist_ok=True)
        
        # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
        self.logs_dir = Path("logs")
        self.logs_dir.mkdir(exist_ok=True)
        
        self._initialized = True
        logger.info("âœ… AI Server Manager ì´ˆê¸°í™” ì™„ë£Œ")
    
    def get_trainer(self, symbol: str = "BTCUSDT") -> ModelTrainer:
        """ModelTrainer ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
        if self.trainer is None or self.trainer.symbol != symbol:
            self.trainer = ModelTrainer(symbol)
        return self.trainer
    
    def get_predictor(self, symbol: str = "BTCUSDT") -> AIPredictor:
        """AIPredictor ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
        if self.predictor is None or self.predictor.symbol != symbol:
            self.predictor = AIPredictor(symbol)
        return self.predictor
    
    def update_training_status(self, updates: Dict):
        """í•™ìŠµ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        self.training_status.update(updates)
        
        # ìƒíƒœ íŒŒì¼ ì €ì¥ (NASì—ì„œ ì½ì„ ìˆ˜ ìˆë„ë¡)
        status_file = Path("training_status.json")
        with open(status_file, 'w') as f:
            json.dump(self.training_status, f, indent=2, default=str)
    
    def add_log(self, message: str, level: str = "INFO"):
        """ë¡œê·¸ ì¶”ê°€"""
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'level': level,
            'message': message
        }
        
        self.training_status['logs'].append(log_entry)
        
        # ìµœëŒ€ 100ê°œ ë¡œê·¸ë§Œ ìœ ì§€
        if len(self.training_status['logs']) > 100:
            self.training_status['logs'] = self.training_status['logs'][-100:]

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
ai_manager = AIServerManager()

# ============================================================================
# API ì—”ë“œí¬ì¸íŠ¸
# ============================================================================

@app.route('/health', methods=['GET'])
def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    return jsonify({
        'status': 'healthy',
        'service': 'AI Server',
        'timestamp': datetime.now().isoformat(),
        'version': '1.0.0'
    })

@app.route('/train', methods=['POST'])
def start_training():
    """AI ëª¨ë¸ í•™ìŠµ ì‹œì‘"""
    try:
        data = request.get_json()
        
        # ì´ë¯¸ í•™ìŠµ ì¤‘ì¸ì§€ í™•ì¸
        if ai_manager.training_status['status'] == 'running':
            return jsonify({
                'success': False,
                'error': 'ì´ë¯¸ í•™ìŠµì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤',
                'status': ai_manager.training_status
            }), 400
        
        # íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        selected_indicators = data.get('indicators', {})
        training_params = data.get('parameters', {})
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        training_params.setdefault('symbol', 'BTCUSDT')
        training_params.setdefault('training_days', 365)
        training_params.setdefault('epochs', 100)
        training_params.setdefault('batch_size', 32)
        training_params.setdefault('learning_rate', 0.001)
        training_params.setdefault('sequence_length', 60)
        training_params.setdefault('validation_split', 20)
        training_params.setdefault('interval', '15')
        
        logger.info(f"ğŸš€ í•™ìŠµ ìš”ì²­ ë°›ìŒ: {training_params['epochs']} epochs")
        
        # í•™ìŠµ ìŠ¤ë ˆë“œ ì‹œì‘
        def run_training():
            try:
                # ìƒíƒœ ì´ˆê¸°í™”
                ai_manager.update_training_status({
                    'status': 'running',
                    'start_time': datetime.now().isoformat(),
                    'end_time': None,
                    'current_epoch': 0,
                    'total_epochs': training_params['epochs'],
                    'accuracy': 0.0,
                    'model_name': None,
                    'error': None,
                    'logs': []
                })
                
                ai_manager.add_log("í•™ìŠµ ì‹œì‘", "INFO")
                
                # ModelTrainer ì¸ìŠ¤í„´ìŠ¤
                trainer = ai_manager.get_trainer(training_params['symbol'])
                
                # ì§„í–‰ë¥  ì½œë°±
                def progress_callback(message):
                    ai_manager.add_log(message, "INFO")
                    
                    # ì—í­ ì •ë³´ ì¶”ì¶œ
                    if "ì—í­" in message:
                        try:
                            parts = message.split('/')
                            if len(parts) == 2:
                                current = int(parts[0].split()[-1])
                                ai_manager.update_training_status({
                                    'current_epoch': current
                                })
                        except:
                            pass
                
                # í•™ìŠµ ì‹œì‘
                success = trainer.start_training(
                    selected_indicators,
                    training_params,
                    progress_callback
                )
                
                if not success:
                    raise Exception("í•™ìŠµ ì‹œì‘ ì‹¤íŒ¨")
                
                # í•™ìŠµ ì™„ë£Œ ëŒ€ê¸°
                while trainer.is_training:
                    time.sleep(5)
                    
                    # ìƒíƒœ ì—…ë°ì´íŠ¸
                    status = trainer.get_training_status()
                    ai_manager.update_training_status({
                        'current_epoch': status.get('current_epoch', 0),
                        'accuracy': status['metrics'].get('accuracy', 0) if status.get('metrics') else 0
                    })
                
                # ìµœì¢… ê²°ê³¼
                final_status = trainer.get_training_status()
                
                if final_status['status'] == 'completed':
                    # ëª¨ë¸ëª… ì°¾ê¸°
                    model_files = list(ai_manager.models_dir.glob("model_*.h5"))
                    if model_files:
                        latest_model = max(model_files, key=lambda x: x.stat().st_mtime)
                        model_name = latest_model.stem
                    else:
                        model_name = f"model_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    
                    ai_manager.update_training_status({
                        'status': 'completed',
                        'end_time': datetime.now().isoformat(),
                        'model_name': model_name,
                        'accuracy': final_status['metrics'].get('accuracy', 0)
                    })
                    
                    ai_manager.add_log(f"í•™ìŠµ ì™„ë£Œ! ì •í™•ë„: {final_status['metrics'].get('accuracy', 0):.3f}", "SUCCESS")
                    logger.info(f"âœ… í•™ìŠµ ì™„ë£Œ: {model_name}")
                    
                else:
                    raise Exception(f"í•™ìŠµ ì‹¤íŒ¨: {final_status.get('status')}")
                    
            except Exception as e:
                logger.error(f"âŒ í•™ìŠµ ì¤‘ ì˜¤ë¥˜: {e}")
                ai_manager.update_training_status({
                    'status': 'failed',
                    'end_time': datetime.now().isoformat(),
                    'error': str(e)
                })
                ai_manager.add_log(f"í•™ìŠµ ì‹¤íŒ¨: {str(e)}", "ERROR")
        
        # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
        ai_manager.training_thread = threading.Thread(target=run_training, daemon=True)
        ai_manager.training_thread.start()
        
        return jsonify({
            'success': True,
            'message': 'í•™ìŠµì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤',
            'training_id': f"train_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            'parameters': training_params
        })
        
    except Exception as e:
        logger.error(f"í•™ìŠµ ì‹œì‘ ì˜¤ë¥˜: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/train/stop', methods=['POST'])
def stop_training():
    """í•™ìŠµ ì¤‘ì§€"""
    try:
        trainer = ai_manager.trainer
        
        if trainer and trainer.is_training:
            success = trainer.stop_training()
            
            if success:
                ai_manager.update_training_status({
                    'status': 'stopped',
                    'end_time': datetime.now().isoformat()
                })
                ai_manager.add_log("í•™ìŠµì´ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ì§€ë¨", "WARNING")
                
                return jsonify({
                    'success': True,
                    'message': 'í•™ìŠµì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤'
                })
        
        return jsonify({
            'success': False,
            'error': 'ì§„í–‰ ì¤‘ì¸ í•™ìŠµì´ ì—†ìŠµë‹ˆë‹¤'
        }), 400
        
    except Exception as e:
        logger.error(f"í•™ìŠµ ì¤‘ì§€ ì˜¤ë¥˜: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/status', methods=['GET'])
def get_training_status():
    """í•™ìŠµ ìƒíƒœ ì¡°íšŒ"""
    try:
        # ì§„í–‰ë¥  ê³„ì‚°
        status = ai_manager.training_status.copy()
        
        if status['total_epochs'] > 0:
            status['progress_percentage'] = (status['current_epoch'] / status['total_epochs']) * 100
        else:
            status['progress_percentage'] = 0
        
        # ê²½ê³¼ ì‹œê°„ ê³„ì‚°
        if status['start_time'] and status['status'] == 'running':
            start_time = datetime.fromisoformat(status['start_time'])
            elapsed = datetime.now() - start_time
            status['elapsed_seconds'] = int(elapsed.total_seconds())
            status['elapsed_formatted'] = str(elapsed).split('.')[0]
        
        return jsonify({
            'success': True,
            'status': status
        })
        
    except Exception as e:
        logger.error(f"ìƒíƒœ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/predict', methods=['POST'])
def predict():
    """ì˜ˆì¸¡ ìˆ˜í–‰"""
    try:
        data = request.get_json()
        
        # ì‹œì¥ ë°ì´í„° ì¶”ì¶œ
        market_data = data.get('market_data')
        if not market_data:
            # ìµœì‹  ë°ì´í„° ìˆ˜ì§‘
            df = ai_manager.data_collector.get_latest_data(interval="15", limit=100)
            if df is None:
                return jsonify({
                    'success': False,
                    'error': 'ì‹œì¥ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
                }), 400
        else:
            # ì „ë‹¬ë°›ì€ ë°ì´í„° ì‚¬ìš©
            import pandas as pd
            df = pd.DataFrame(market_data)
        
        # ì˜ˆì¸¡ê¸° ì¸ìŠ¤í„´ìŠ¤
        predictor = ai_manager.get_predictor()
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        prediction_result = predictor.predict(df)
        
        return jsonify({
            'success': True,
            'prediction': prediction_result
        })
        
    except Exception as e:
        logger.error(f"ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/models', methods=['GET'])
def get_models():
    """ëª¨ë¸ ëª©ë¡ ì¡°íšŒ"""
    try:
        model_files = list(ai_manager.models_dir.glob("model_*.h5"))
        models = []
        
        for model_file in model_files:
            model_name = model_file.stem
            info_file = ai_manager.models_dir / f"{model_name}_info.json"
            
            if info_file.exists():
                with open(info_file, 'r') as f:
                    info = json.load(f)
            else:
                info = {}
            
            models.append({
                'name': model_name,
                'created_at': info.get('created_at', model_file.stat().st_mtime),
                'accuracy': info.get('accuracy', 0),
                'size_mb': round(model_file.stat().st_size / 1024 / 1024, 2)
            })
        
        # ìµœì‹ ìˆœ ì •ë ¬
        models.sort(key=lambda x: x['created_at'], reverse=True)
        
        return jsonify({
            'success': True,
            'models': models,
            'count': len(models)
        })
        
    except Exception as e:
        logger.error(f"ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/models/<model_name>', methods=['GET'])
def get_model_info(model_name):
    """íŠ¹ì • ëª¨ë¸ ì •ë³´ ì¡°íšŒ"""
    try:
        model_file = ai_manager.models_dir / f"{model_name}.h5"
        
        if not model_file.exists():
            return jsonify({
                'success': False,
                'error': 'ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
            }), 404
        
        info_file = ai_manager.models_dir / f"{model_name}_info.json"
        
        if info_file.exists():
            with open(info_file, 'r') as f:
                info = json.load(f)
        else:
            info = {'name': model_name}
        
        # íŒŒì¼ í¬ê¸° ì¶”ê°€
        info['size_mb'] = round(model_file.stat().st_size / 1024 / 1024, 2)
        
        # ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ í™•ì¸
        scaler_file = ai_manager.models_dir / f"{model_name}_scaler.pkl"
        info['has_scaler'] = scaler_file.exists()
        
        return jsonify({
            'success': True,
            'model': info
        })
        
    except Exception as e:
        logger.error(f"ëª¨ë¸ ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/logs', methods=['GET'])
def get_logs():
    """í•™ìŠµ ë¡œê·¸ ì¡°íšŒ"""
    try:
        # ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°
        lines = request.args.get('lines', 50, type=int)
        
        # ë©”ëª¨ë¦¬ ë¡œê·¸
        memory_logs = ai_manager.training_status.get('logs', [])
        
        # íŒŒì¼ ë¡œê·¸ (ì˜µì…˜)
        log_file = Path("logs/training.log")
        file_logs = []
        
        if log_file.exists():
            with open(log_file, 'r') as f:
                file_logs = f.readlines()[-lines:]
        
        return jsonify({
            'success': True,
            'memory_logs': memory_logs[-lines:],
            'file_logs': file_logs
        })
        
    except Exception as e:
        logger.error(f"ë¡œê·¸ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/system/info', methods=['GET'])
def get_system_info():
    """ì‹œìŠ¤í…œ ì •ë³´"""
    try:
        import tensorflow as tf
        
        # GPU ì •ë³´
        gpus = tf.config.list_physical_devices('GPU')
        gpu_info = {
            'available': len(gpus) > 0,
            'count': len(gpus),
            'devices': [gpu.name for gpu in gpus]
        }
        
        # ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰
        models_size = sum(f.stat().st_size for f in ai_manager.models_dir.glob("*")) if ai_manager.models_dir.exists() else 0
        
        system_info = {
            'gpu': gpu_info,
            'tensorflow_version': tf.__version__,
            'models_directory': str(ai_manager.models_dir),
            'models_count': len(list(ai_manager.models_dir.glob("model_*.h5"))),
            'storage_mb': round(models_size / 1024 / 1024, 2),
            'server_time': datetime.now().isoformat()
        }
        
        return jsonify({
            'success': True,
            'system': system_info
        })
        
    except Exception as e:
        logger.error(f"ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# ============================================================================
# ì—ëŸ¬ í•¸ë“¤ëŸ¬
# ============================================================================

@app.errorhandler(404)
def not_found(error):
    return jsonify({
        'success': False,
        'error': 'ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
    }), 404

@app.errorhandler(500)
def internal_error(error):
    logger.error(f"Internal server error: {error}")
    return jsonify({
        'success': False,
        'error': 'ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤'
    }), 500

# ============================================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================================

if __name__ == '__main__':
    print("="*60)
    print("ğŸš€ NHBot AI Server ì‹œì‘")
    print("="*60)
    print(f"ğŸ“ ëª¨ë¸ ë””ë ‰í† ë¦¬: {ai_manager.models_dir}")
    print(f"ğŸ“ ë¡œê·¸ ë””ë ‰í† ë¦¬: {ai_manager.logs_dir}")
    
    # TensorFlow GPU í™•ì¸
    import tensorflow as tf
    gpus = tf.config.list_physical_devices('GPU')
    if gpus:
        print(f"ğŸ® GPU ê°ì§€ë¨: {len(gpus)}ê°œ")
        for gpu in gpus:
            print(f"   - {gpu.name}")
    else:
        print("ğŸ’» CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤")
    
    print("="*60)
    print("ğŸ“¡ API ì—”ë“œí¬ì¸íŠ¸:")
    print("   POST /train         - í•™ìŠµ ì‹œì‘")
    print("   POST /train/stop    - í•™ìŠµ ì¤‘ì§€")
    print("   GET  /status        - í•™ìŠµ ìƒíƒœ")
    print("   POST /predict       - ì˜ˆì¸¡ ìˆ˜í–‰")
    print("   GET  /models        - ëª¨ë¸ ëª©ë¡")
    print("   GET  /system/info   - ì‹œìŠ¤í…œ ì •ë³´")
    print("="*60)
    
    # Flask ì„œë²„ ì‹¤í–‰
    app.run(host='0.0.0.0', port=5000, debug=False, threaded=True)