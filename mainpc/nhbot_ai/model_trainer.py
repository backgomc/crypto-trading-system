# íŒŒì¼ ê²½ë¡œ: mainpc/nhbot_ai/model_trainer.py
# ì½”ë“œëª…: AI ëª¨ë¸ í•™ìŠµ í´ë˜ìŠ¤ (3-í´ë˜ìŠ¤ ë¶„ë¥˜, MACD ì œì™¸ ë²„ì „)

import tensorflow as tf
import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.utils.class_weight import compute_class_weight
import pickle
import json
from datetime import datetime
from pathlib import Path
import threading
import time
from typing import Dict, List, Optional, Tuple, Callable

class ModelTrainer:
    """AI ëª¨ë¸ í•™ìŠµ í´ë˜ìŠ¤ (3-í´ë˜ìŠ¤: none/long/short)"""
    
    def __init__(self, symbol: str = "BTCUSDT"):
        self.symbol = symbol
        
        # í•™ìŠµ ìƒíƒœ ê´€ë¦¬
        self.is_training = False
        self.training_thread = None
        self.training_status = {
            "status": "idle",  # idle, running, completed, failed
            "current_epoch": 0,
            "total_epochs": 0,
            "current_batch": 0,
            "total_batches": 0,
            "metrics": {
                "loss": 0.0,
                "accuracy": 0.0,
                "val_loss": 0.0,
                "val_accuracy": 0.0
            },
            "start_time": None,
            "progress_callback": None
        }
        
        # ğŸ†• MACD ì œì™¸í•œ í•„ìˆ˜ ì§€í‘œ
        self.essential_indicators = {
            # ê°€ê²© ì›€ì§ì„
            "price": ["close", "price_change", "price_change_abs", "hl_range"],
            
            # ëª¨ë©˜í…€ (MACD ì™„ì „ ì œì™¸!)
            "rsi": ["rsi_14", "rsi_30"],
            "stoch": ["stoch_k", "stoch_d"],
            "williams": ["williams_r"],
            
            # ì¶”ì„¸ ê°•ë„
            "adx": ["adx", "adx_slope"],
            "aroon": ["aroon_up", "aroon_down", "aroon_oscillator"],
            
            # ë³€ë™ì„±
            "bb": ["bb_position", "bb_width"],
            "atr": ["atr"],
            
            # ê±°ë˜ëŸ‰
            "volume": ["volume_ratio", "cvd", "cvd_slope", "mfi"],
            
            # íŒ¨í„´
            "consecutive": ["consecutive_up", "consecutive_down"],
            "trend": ["1h_trend", "4h_trend", "trend_alignment", "trend_strength"]
        }
        
        self.optional_indicators = {
            # ì„ íƒì  ì§€í‘œ
            "sma": ["sma_20", "close_vs_sma_20", "sma_20_slope"],
            "ema": ["ema_20", "ema_50", "ema_20_slope"],
            "volatility": ["volatility_10", "volatility_20"],
            "vwap": ["vwap"],
            "pivot": ["pivot_position"],
            "zscore": ["zscore_20", "zscore_50"]
        }
        
        # ì „ì²´ ì§€í‘œ í†µí•©
        self.indicator_mapping = {**self.essential_indicators, **self.optional_indicators}
        
        print(f"âœ… ModelTrainer ì´ˆê¸°í™” ì™„ë£Œ: {symbol}")
        print(f"   ëª¨ë“œ: 3-í´ë˜ìŠ¤ ë¶„ë¥˜ (none/long/short)")
    
    def start_training(self, 
                      selected_indicators: Dict[str, bool],
                      training_params: Dict,
                      progress_callback: Optional[Callable] = None) -> bool:
        """ë¹„ë™ê¸° í•™ìŠµ ì‹œì‘"""
        if self.is_training:
            print("âŒ ì´ë¯¸ í•™ìŠµì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.")
            return False
        
        try:
            # í•™ìŠµ ìƒíƒœ ì´ˆê¸°í™”
            self.training_status = {
                "status": "running",
                "current_epoch": 0,
                "total_epochs": training_params.get("epochs", 100),
                "current_batch": 0,
                "total_batches": 0,
                "metrics": {"loss": 0.0, "accuracy": 0.0, "val_loss": 0.0, "val_accuracy": 0.0},
                "start_time": datetime.now(),
                "progress_callback": progress_callback
            }
            
            # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ í•™ìŠµ ì‹¤í–‰
            self.training_thread = threading.Thread(
                target=self._train_model_async,
                args=(selected_indicators, training_params),
                daemon=True
            )
            
            self.is_training = True
            self.training_thread.start()
            
            print("ğŸš€ AI ëª¨ë¸ í•™ìŠµì„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œì‘í–ˆìŠµë‹ˆë‹¤.")
            return True
            
        except Exception as e:
            print(f"âŒ í•™ìŠµ ì‹œì‘ ì‹¤íŒ¨: {e}")
            self.training_status["status"] = "failed"
            return False
    
    def stop_training(self) -> bool:
        """í•™ìŠµ ì¤‘ì§€"""
        if not self.is_training:
            return False
        
        try:
            self.is_training = False
            self.training_status["status"] = "stopped"
            
            if self.training_thread and self.training_thread.is_alive():
                self.training_thread.join(timeout=5)
            
            print("â¹ï¸ AI ëª¨ë¸ í•™ìŠµì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return True
            
        except Exception as e:
            print(f"âŒ í•™ìŠµ ì¤‘ì§€ ì‹¤íŒ¨: {e}")
            return False
    
    def get_training_status(self) -> Dict:
        """í˜„ì¬ í•™ìŠµ ìƒíƒœ ì¡°íšŒ"""
        return self.training_status.copy()
    
    def _train_model_async(self, selected_indicators: Dict[str, bool], training_params: Dict):
        """ë¹„ë™ê¸° í•™ìŠµ ì‹¤í–‰ (ë‚´ë¶€ ë©”ì„œë“œ)"""
        try:
            print("ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
            self._update_progress_callback("ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            
            # ìŠ¤ë ˆë“œ ë‚´ë¶€ì—ì„œ DataCollector ìƒì„±
            from .data_collector import DataCollector
            data_collector = DataCollector(self.symbol)
            
            # 1. ë°ì´í„° ìˆ˜ì§‘
            training_days = training_params.get("training_days", 365)
            interval = training_params.get("interval", "15")
            
            df = data_collector.collect_historical_data(interval=interval, days=training_days)
            if df is None or len(df) < 1000:
                raise Exception("ì¶©ë¶„í•œ í•™ìŠµ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # 2. ì„ íƒëœ ì§€í‘œ ì¶”ì¶œ (MACD ì œì™¸)
            print("ğŸ“‹ ì„ íƒëœ ì§€í‘œ ì¶”ì¶œ ì¤‘...")
            self._update_progress_callback("ì„ íƒëœ ì§€í‘œ ì¶”ì¶œ ì¤‘...")
            feature_data = self._prepare_features(df, selected_indicators)
            
            # 3. ğŸ†• 3-í´ë˜ìŠ¤ ë¼ë²¨ë§ (ì¶”ì„¸ ì „í™˜ ë°©í–¥ êµ¬ë¶„)
            print("ğŸ·ï¸ ë¼ë²¨ ìƒì„± ì¤‘ (3-í´ë˜ìŠ¤)...")
            labels = self._create_labels_3class(df)
            
            # 4. í•™ìŠµ ë°ì´í„° ì¤€ë¹„
            print("ğŸ“ˆ í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì¤‘...")
            X, y, scaler = self._prepare_training_data(feature_data, labels, training_params)
            
            # 5. ğŸ†• 3-í´ë˜ìŠ¤ ëª¨ë¸ êµ¬ì„±
            print("ğŸ§  ëª¨ë¸ êµ¬ì„± ì¤‘...")
            model = self._build_model_3class(X.shape, training_params)
            
            # 6. í•™ìŠµ ì‹¤í–‰
            print("ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
            self._update_progress_callback("ëª¨ë¸ í•™ìŠµ ì¤‘...")
            
            history = self._train_with_progress(model, X, y, training_params)
            
            # 7. ëª¨ë¸ í‰ê°€
            print("ğŸ“Š ëª¨ë¸ í‰ê°€ ì¤‘...")
            accuracy = self._evaluate_model_3class(model, X, y)
            
            # 8. ëª¨ë¸ ì €ì¥
            print("ğŸ’¾ ëª¨ë¸ ì €ì¥ ì¤‘...")
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            model_name = f"model_3class_{timestamp}"
            
            model_path = Path("models") / f"{model_name}.h5"
            scaler_path = Path("models") / f"{model_name}_scaler.pkl"
            info_path = Path("models") / f"{model_name}_info.json"
            
            model_path.parent.mkdir(exist_ok=True)
            model.save(str(model_path))
            
            with open(scaler_path, 'wb') as f:
                pickle.dump(scaler, f)
            
            # í•™ìŠµ ì •ë³´ ì €ì¥
            training_info = {
                "model_name": model_name,
                "model_type": "3-class",  # ëª¨ë¸ íƒ€ì… ëª…ì‹œ
                "classes": ["none", "long", "short"],
                "accuracy": float(accuracy),
                "parameters": training_params,
                "indicators": selected_indicators,
                "training_duration": (datetime.now() - self.training_status["start_time"]).total_seconds(),
                "feature_columns": list(feature_data.columns),
                "data_shape": [int(x) for x in X.shape],
                "created_at": datetime.now().isoformat(),
                "symbol": self.symbol
            }
            
            with open(info_path, 'w') as f:
                json.dump(training_info, f, indent=2)
            
            # í•™ìŠµ ì™„ë£Œ
            self.training_status["status"] = "completed"
            self.training_status["metrics"]["accuracy"] = accuracy
            
            print(f"âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ! ì •í™•ë„: {accuracy:.3f}")
            print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {model_path}")
            self._update_progress_callback(f"í•™ìŠµ ì™„ë£Œ! ì •í™•ë„: {accuracy:.1%}")
            
        except Exception as e:
            print(f"âŒ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            self.training_status["status"] = "failed"
            self._update_progress_callback(f"í•™ìŠµ ì‹¤íŒ¨: {str(e)}")
        
        finally:
            self.is_training = False
    
    def _prepare_features(self, df: pd.DataFrame, selected_indicators: Dict[str, bool]) -> pd.DataFrame:
        """ì„ íƒëœ ì§€í‘œë§Œ ì¶”ì¶œ (MACD ì™„ì „ ì œì™¸)"""
        feature_columns = []
        
        # MACD ê´€ë ¨ ì»¬ëŸ¼ ì œì™¸ ë¦¬ìŠ¤íŠ¸
        macd_columns = ['macd', 'macd_signal', 'macd_histogram']
        
        print("ğŸ“‹ ì„ íƒëœ ì§€í‘œ (MACD ì œì™¸):")
        
        # í•„ìˆ˜ ì§€í‘œëŠ” í•­ìƒ í¬í•¨
        for indicator, columns in self.essential_indicators.items():
            # MACD ì»¬ëŸ¼ ì œì™¸
            existing_columns = [
                col for col in columns 
                if col in df.columns and col not in macd_columns
            ]
            feature_columns.extend(existing_columns)
            print(f"   âœ… {indicator}: {len(existing_columns)}ê°œ ì»¬ëŸ¼ (í•„ìˆ˜)")
        
        # ì„ íƒì  ì§€í‘œ
        for indicator, selected in selected_indicators.items():
            if selected and indicator in self.optional_indicators:
                columns = self.optional_indicators[indicator]
                existing_columns = [
                    col for col in columns 
                    if col in df.columns and col not in macd_columns
                ]
                feature_columns.extend(existing_columns)
                print(f"   âœ… {indicator}: {len(existing_columns)}ê°œ ì»¬ëŸ¼ (ì„ íƒ)")
        
        if not feature_columns:
            raise Exception("ì„ íƒëœ ì§€í‘œê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì¤‘ë³µ ì œê±°
        feature_columns = list(set(feature_columns))
        
        # MACD ì»¬ëŸ¼ì´ ì‹¤ìˆ˜ë¡œ í¬í•¨ë˜ì—ˆëŠ”ì§€ ìµœì¢… ì²´í¬
        feature_columns = [col for col in feature_columns if col not in macd_columns]
        
        print(f"ğŸ“Š ì´ íŠ¹ì„± ê°œìˆ˜: {len(feature_columns)}ê°œ")
        print(f"   (MACD ê´€ë ¨ ì§€í‘œ ì œì™¸ í™•ì¸ ì™„ë£Œ)")
        
        return df[feature_columns].dropna()
    
def _create_labels_3class(self, df: pd.DataFrame) -> pd.Series:
    """ğŸ†• ì§„ì§œ ì¶”ì„¸ ì „í™˜ ë¼ë²¨ë§ (ì§€ì†ì„± í™•ì¸)"""
    
    labels = pd.Series(0, index=df.index)  # ê¸°ë³¸ê°’: none
    
    # ============================================================================
    # 1. ê¸°ë³¸ ì§€í‘œë“¤ ì¶”ì¶œ
    # ============================================================================
    
    rsi = df['rsi_14'] if 'rsi_14' in df.columns else pd.Series(50, index=df.index)
    adx = df['adx'] if 'adx' in df.columns else pd.Series(25, index=df.index)  
    bb_pos = df['bb_position'] if 'bb_position' in df.columns else pd.Series(0.5, index=df.index)
    aroon_osc = df['aroon_oscillator'] if 'aroon_oscillator' in df.columns else pd.Series(0, index=df.index)
    atr = df['atr'] if 'atr' in df.columns else df['close'].rolling(14).std()
    volume_ratio = df['volume_ratio'] if 'volume_ratio' in df.columns else pd.Series(1, index=df.index)
    consec_up = df['consecutive_up'] if 'consecutive_up' in df.columns else pd.Series(0, index=df.index)
    consec_down = df['consecutive_down'] if 'consecutive_down' in df.columns else pd.Series(0, index=df.index)
    
    # ============================================================================
    # 2. ì¶”ì„¸ ì „í™˜ ì§€ì†ì„± í™•ì¸ (í•µì‹¬ ê°œì„ !)
    # ============================================================================
    
    current_close = df['close']
    transaction_cost = 0.0011  # 0.11%
    
    # ğŸ¯ ì¶”ì„¸ ì „í™˜ ì„±ê³µ ì¡°ê±´: "ì§€ì†ì„±" í™•ì¸
    def check_trend_reversal_success(current_idx, direction):
        """
        ì¶”ì„¸ ì „í™˜ ì„±ê³µ ì—¬ë¶€ í™•ì¸
        - direction: 1 (ìƒìŠ¹), -1 (í•˜ë½)
        - ìµœì†Œ 3ê°œ ë´‰(45ë¶„) ë™ì•ˆ ì§€ì†ë˜ì–´ì•¼ í•¨
        """
        if current_idx >= len(current_close) - 4:  # ë°ì´í„° ë¶€ì¡±
            return False
            
        entry_price = current_close.iloc[current_idx]
        
        # ğŸ“Š ì§€ì†ì„± í™•ì¸ ê¸°ì¤€
        min_duration = 3  # ìµœì†Œ 3ê°œ ë´‰ (45ë¶„)
        min_profit_threshold = transaction_cost * 2  # ìˆ˜ìˆ˜ë£Œì˜ 2ë°° (0.22%)
        max_drawdown = transaction_cost  # ìµœëŒ€ ë‚™í­ = ìˆ˜ìˆ˜ë£Œë§Œí¼ (0.11%)
        
        success_conditions = []
        
        for i in range(1, min_duration + 1):
            if current_idx + i >= len(current_close):
                return False
                
            future_price = current_close.iloc[current_idx + i]
            future_return = (future_price - entry_price) / entry_price
            
            if direction == 1:  # ìƒìŠ¹ ì „í™˜ ì²´í¬
                # ì¡°ê±´ 1: ìµœì†Œ ìˆ˜ìµë¥  ë‹¬ì„±
                profit_achieved = future_return > min_profit_threshold
                
                # ì¡°ê±´ 2: ì¤‘ê°„ì— ì†ì ˆì„  ì•ˆ í„°ì§ (entry_price ê¸°ì¤€ -0.11% ì´í•˜ë¡œ ì•ˆë–¨ì–´ì§)
                max_loss_ok = True
                for j in range(1, i + 1):
                    temp_price = current_close.iloc[current_idx + j]
                    temp_return = (temp_price - entry_price) / entry_price
                    if temp_return < -max_drawdown:
                        max_loss_ok = False
                        break
                
                success_conditions.append(profit_achieved and max_loss_ok)
                
            else:  # í•˜ë½ ì „í™˜ ì²´í¬ (direction == -1)
                # ì¡°ê±´ 1: ìµœì†Œ ìˆ˜ìµë¥  ë‹¬ì„± (Shortì´ë¯€ë¡œ ë°˜ëŒ€)
                profit_achieved = future_return < -min_profit_threshold
                
                # ì¡°ê±´ 2: ì¤‘ê°„ì— ì†ì ˆì„  ì•ˆ í„°ì§ (entry_price ê¸°ì¤€ +0.11% ì´ìƒìœ¼ë¡œ ì•ˆì˜¬ë¼ê°)
                max_loss_ok = True
                for j in range(1, i + 1):
                    temp_price = current_close.iloc[current_idx + j]
                    temp_return = (temp_price - entry_price) / entry_price
                    if temp_return > max_drawdown:
                        max_loss_ok = False
                        break
                
                success_conditions.append(profit_achieved and max_loss_ok)
        
        # ğŸ† ì„±ê³µ ì¡°ê±´: 3ê°œ ë´‰ ì¤‘ ìµœì†Œ 2ê°œ ì´ìƒ ì„±ê³µ
        return sum(success_conditions) >= 2
    
    # ============================================================================
    # 3. AI ì§„ì… ì¡°ê±´ (ê¸°ì¡´ê³¼ ë™ì¼í•˜ì§€ë§Œ ì¡°ê¸ˆ ë” ì—„ê²©í•˜ê²Œ)
    # ============================================================================
    
    # Long ì§„ì… ì‹ í˜¸ ì¡°ê±´
    long_entry_conditions = (
        # ì¡°ê±´ 1: RSI ê³¼ë§¤ë„ íƒˆì¶œ (ë” ì—„ê²©)
        ((rsi > 30) & (rsi < 50)) &
        
        # ì¡°ê±´ 2: ë³¼ë¦°ì € ë°´ë“œ ìœ„ì¹˜ (ë” ì—„ê²©)
        ((bb_pos > 0.2) & (bb_pos < 0.4)) &
        
        # ì¡°ê±´ 3: Aroon ìƒìŠ¹ ëª¨ë©˜í…€
        (aroon_osc > -20) &
        
        # ì¡°ê±´ 4: ì—°ì† í•˜ë½ í›„ ì•ˆì •í™” (ë” ì—„ê²©)
        ((consec_down >= 2) & (consec_down <= 6))
    )
    
    # Short ì§„ì… ì‹ í˜¸ ì¡°ê±´  
    short_entry_conditions = (
        # ì¡°ê±´ 1: RSI ê³¼ë§¤ìˆ˜ í•˜ë½ (ë” ì—„ê²©)
        ((rsi > 50) & (rsi < 70)) &
        
        # ì¡°ê±´ 2: ë³¼ë¦°ì € ë°´ë“œ ìœ„ì¹˜ (ë” ì—„ê²©)
        ((bb_pos > 0.6) & (bb_pos < 0.8)) &
        
        # ì¡°ê±´ 3: Aroon í•˜ë½ ëª¨ë©˜í…€
        (aroon_osc < 20) &
        
        # ì¡°ê±´ 4: ì—°ì† ìƒìŠ¹ í›„ ì•ˆì •í™” (ë” ì—„ê²©)
        ((consec_up >= 2) & (consec_up <= 6))
    )
    
    # ============================================================================
    # 4. ì‹œì¥ í™˜ê²½ í•„í„°ë§ (ê¸°ì¡´ê³¼ ë™ì¼)
    # ============================================================================
    
    extreme_trend = (
        (adx > 45) |
        (consec_up > 8) |
        (consec_down > 8) |
        (volume_ratio < 0.4)
    )
    
    low_volatility = atr < (df['close'] * 0.003)  # 0.3%ë¡œ ì¡°ê¸ˆ ì˜¬ë¦¼
    
    # ============================================================================
    # 5. ë¼ë²¨ í• ë‹¹ (ì§€ì†ì„± í™•ì¸)
    # ============================================================================
    
    print("ğŸ” ì¶”ì„¸ ì „í™˜ ì§€ì†ì„± í™•ì¸ ì¤‘...")
    
    for i in range(len(df) - 4):  # ë§ˆì§€ë§‰ 4ê°œëŠ” ë¯¸ë˜ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ì œì™¸
        
        # Long ì‹ í˜¸ ì²´í¬
        if (long_entry_conditions.iloc[i] and 
            not extreme_trend.iloc[i] and 
            not low_volatility.iloc[i]):
            
            if check_trend_reversal_success(i, direction=1):
                labels.iloc[i] = 1  # Long ì„±ê³µ
        
        # Short ì‹ í˜¸ ì²´í¬
        if (short_entry_conditions.iloc[i] and 
            not extreme_trend.iloc[i] and 
            not low_volatility.iloc[i]):
            
            if check_trend_reversal_success(i, direction=-1):
                labels.iloc[i] = 2  # Short ì„±ê³µ
    
    # ============================================================================
    # 6. í†µê³„ ë° ê²€ì¦
    # ============================================================================
    
    valid_count = len(labels) - 4
    none_count = (labels == 0).sum()
    long_count = (labels == 1).sum()
    short_count = (labels == 2).sum()
    
    print(f"ğŸ¯ ì§€ì†ì„± ê¸°ë°˜ ë¼ë²¨ ë¶„í¬:")
    print(f"   - None (í´ë˜ìŠ¤ 0): {none_count:,}ê°œ ({none_count/valid_count*100:.1f}%)")
    print(f"   - Long (í´ë˜ìŠ¤ 1): {long_count:,}ê°œ ({long_count/valid_count*100:.1f}%)")
    print(f"   - Short (í´ë˜ìŠ¤ 2): {short_count:,}ê°œ ({short_count/valid_count*100:.1f}%)")
    
    # ============================================================================
    # 7. ë¼ë²¨ í’ˆì§ˆ ê²€ì¦ (ì‹¤ì œ ì„±ê³¼ í™•ì¸)
    # ============================================================================
    
    if long_count > 0:
        # Long ë¼ë²¨ì˜ 3ë´‰ í›„ í‰ê·  ìˆ˜ìµë¥ 
        long_3candle_returns = []
        for i in range(len(labels)):
            if labels.iloc[i] == 1 and i + 3 < len(df):
                entry_price = current_close.iloc[i]
                exit_price = current_close.iloc[i + 3]
                return_rate = (exit_price - entry_price) / entry_price
                long_3candle_returns.append(return_rate)
        
        if long_3candle_returns:
            avg_return = sum(long_3candle_returns) / len(long_3candle_returns)
            success_rate = sum(1 for r in long_3candle_returns if r > transaction_cost) / len(long_3candle_returns)
            
            print(f"ğŸ“ˆ Long ë¼ë²¨ ê²€ì¦ (3ë´‰ í›„):")
            print(f"   - ì„±ê³µë¥ : {success_rate*100:.1f}%")
            print(f"   - í‰ê·  ìˆ˜ìµë¥ : {avg_return*100:.2f}%")
            print(f"   - ì˜ˆìƒ ìˆœìˆ˜ìµ: {(avg_return - transaction_cost)*100:.2f}%")
    
    if short_count > 0:
        # Short ë¼ë²¨ì˜ 3ë´‰ í›„ í‰ê·  ìˆ˜ìµë¥ 
        short_3candle_returns = []
        for i in range(len(labels)):
            if labels.iloc[i] == 2 and i + 3 < len(df):
                entry_price = current_close.iloc[i]
                exit_price = current_close.iloc[i + 3]
                return_rate = (entry_price - exit_price) / entry_price  # ShortëŠ” ë°˜ëŒ€
                short_3candle_returns.append(return_rate)
        
        if short_3candle_returns:
            avg_return = sum(short_3candle_returns) / len(short_3candle_returns)
            success_rate = sum(1 for r in short_3candle_returns if r > transaction_cost) / len(short_3candle_returns)
            
            print(f"ğŸ“‰ Short ë¼ë²¨ ê²€ì¦ (3ë´‰ í›„):")
            print(f"   - ì„±ê³µë¥ : {success_rate*100:.1f}%")
            print(f"   - í‰ê·  ìˆ˜ìµë¥ : {avg_return*100:.2f}%")
            print(f"   - ì˜ˆìƒ ìˆœìˆ˜ìµ: {(avg_return - transaction_cost)*100:.2f}%")
    
    # ì‹ í˜¸ í’ˆì§ˆ í‰ê°€
    total_signals = long_count + short_count
    signal_ratio = total_signals / valid_count
    
    if signal_ratio < 0.002:  # 0.2% ë¯¸ë§Œ
        print("âš ï¸ ì§„ì§œ ì¶”ì„¸ ì „í™˜ì´ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤ - ì¡°ê±´ì„ ì™„í™”í•˜ì„¸ìš”")
    elif signal_ratio > 0.01:  # 1% ì´ˆê³¼  
        print("âš ï¸ ì‹ í˜¸ê°€ ì—¬ì „íˆ ë§ìŠµë‹ˆë‹¤ - ì¡°ê±´ì„ ë” ê°•í™”í•˜ì„¸ìš”")
    else:
        print("âœ… ì ì ˆí•œ ì§„ì§œ ì¶”ì„¸ ì „í™˜ ë¹„ìœ¨ì…ë‹ˆë‹¤")
    
    print(f"\nğŸ”¥ ì§„ì§œ ì¶”ì„¸ ì „í™˜ í¬ì°©ë¥ : {signal_ratio*100:.3f}%")
    print(f"   (ì „ì²´ {valid_count:,}ê°œ ì¤‘ {total_signals:,}ê°œ)")
    
    return labels
    
    def _prepare_training_data(self, feature_data: pd.DataFrame, labels: pd.Series, 
                              training_params: Dict) -> Tuple[np.ndarray, np.ndarray, MinMaxScaler]:
        """í•™ìŠµ ë°ì´í„° ì¤€ë¹„ (ì‹œí€€ìŠ¤ ë°ì´í„°ë¡œ ë³€í™˜)"""
        
        sequence_length = training_params.get("sequence_length", 60)
        
        # ë°ì´í„° ì •ê·œí™”
        scaler = MinMaxScaler()
        scaled_features = scaler.fit_transform(feature_data)
        
        # ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±
        X, y = [], []
        
        for i in range(sequence_length, len(scaled_features)):
            if not self.is_training:
                break
                
            X.append(scaled_features[i-sequence_length:i])
            y.append(labels.iloc[i])
        
        X = np.array(X)
        y = np.array(y)
        
        print(f"ğŸ“Š í•™ìŠµ ë°ì´í„° í˜•íƒœ: X={X.shape}, y={y.shape}")
        print(f"   - ì‹œí€€ìŠ¤ ê¸¸ì´: {sequence_length}")
        print(f"   - íŠ¹ì„± ê°œìˆ˜: {X.shape[2] if len(X.shape) > 2 else 0}")
        print(f"   - ìƒ˜í”Œ ê°œìˆ˜: {X.shape[0]}")
        
        return X, y, scaler
    
    def _build_model_3class(self, input_shape: Tuple, training_params: Dict) -> tf.keras.Model:
        """ğŸ†• 3-í´ë˜ìŠ¤ ë¶„ë¥˜ë¥¼ ìœ„í•œ LSTM ëª¨ë¸"""
        
        model = Sequential([
            # ì²« ë²ˆì§¸ LSTM ë ˆì´ì–´ (ì¦ê°€)
            LSTM(128, return_sequences=True, input_shape=input_shape[1:]),
            Dropout(0.3),
            BatchNormalization(),
            
            # ë‘ ë²ˆì§¸ LSTM ë ˆì´ì–´
            LSTM(64, return_sequences=False),
            Dropout(0.3),
            BatchNormalization(),
            
            # Dense ë ˆì´ì–´ë“¤
            Dense(64, activation='relu'),
            Dropout(0.4),
            Dense(32, activation='relu'),
            Dropout(0.3),
            Dense(16, activation='relu'),
            Dropout(0.2),
            
            # ğŸ†• ì¶œë ¥ ë ˆì´ì–´ (3-í´ë˜ìŠ¤)
            Dense(3, activation='softmax')  # 3ê°œ í´ë˜ìŠ¤: none, long, short
        ])
        
        # ì»´íŒŒì¼
        learning_rate = training_params.get("learning_rate", 0.001)
        optimizer = Adam(learning_rate=learning_rate)
        
        model.compile(
            optimizer=optimizer,
            loss='sparse_categorical_crossentropy',  # 3-í´ë˜ìŠ¤ìš© loss
            metrics=['accuracy', 
                    tf.keras.metrics.SparseCategoricalAccuracy(name='categorical_accuracy')]
        )
        
        print("ğŸ§  3-í´ë˜ìŠ¤ ëª¨ë¸ êµ¬ì¡°:")
        model.summary()
        
        return model
    
    def _train_with_progress(self, model: tf.keras.Model, X: np.ndarray, y: np.ndarray, 
                           training_params: Dict) -> tf.keras.callbacks.History:
        """ì§„í–‰ë¥  ëª¨ë‹ˆí„°ë§ê³¼ í•¨ê»˜ í•™ìŠµ ì‹¤í–‰"""
        
        # í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„í• 
        validation_split = training_params.get("validation_split", 20) / 100
        X_train, X_val, y_train, y_val = train_test_split(
            X, y, test_size=validation_split, random_state=42, stratify=y
        )
        
        # ğŸ†• í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° (ë¶ˆê· í˜• í•´ê²°)
        unique_classes = np.unique(y_train)
        class_weights = compute_class_weight(
            'balanced',
            classes=unique_classes,
            y=y_train
        )
        class_weight_dict = {int(unique_classes[i]): class_weights[i] for i in range(len(unique_classes))}
        
        print(f"âš–ï¸ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜:")
        print(f"   - None (0): {class_weight_dict.get(0, 1.0):.2f}")
        print(f"   - Long (1): {class_weight_dict.get(1, 1.0):.2f}")
        print(f"   - Short (2): {class_weight_dict.get(2, 1.0):.2f}")
        
        # ë°°ì¹˜ í¬ê¸°
        batch_size = training_params.get("batch_size", 32)
        epochs = training_params.get("epochs", 100)
        
        # ì´ ë°°ì¹˜ ìˆ˜ ê³„ì‚°
        total_batches = len(X_train) // batch_size
        self.training_status["total_batches"] = total_batches
        
        # ì½œë°± í•¨ìˆ˜ë“¤
        callbacks = [
            EarlyStopping(
                patience=20,  # 10 â†’ 20ìœ¼ë¡œ ì¦ê°€
                restore_best_weights=True,
                monitor='val_loss',
                verbose=1
            ),
            ReduceLROnPlateau(
                factor=0.5, 
                patience=10,  # 5 â†’ 10ìœ¼ë¡œ ì¦ê°€
                min_lr=1e-7,
                verbose=1
            ),
            TrainingProgressCallback(self)
        ]
        
        # í•™ìŠµ ì‹¤í–‰ (í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©)
        history = model.fit(
            X_train, y_train,
            batch_size=batch_size,
            epochs=epochs,
            validation_data=(X_val, y_val),
            class_weight=class_weight_dict,  # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©
            callbacks=callbacks,
            verbose=0
        )
        
        return history
    
    def _evaluate_model_3class(self, model: tf.keras.Model, X: np.ndarray, y: np.ndarray) -> float:
        """ğŸ†• 3-í´ë˜ìŠ¤ ëª¨ë¸ í‰ê°€"""
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        y_pred_proba = model.predict(X, verbose=0)
        y_pred = np.argmax(y_pred_proba, axis=1)
        
        # ì •í™•ë„ ê³„ì‚°
        accuracy = accuracy_score(y, y_pred)
        
        # í˜¼ë™ í–‰ë ¬
        cm = confusion_matrix(y, y_pred)
        
        # ìƒì„¸ ë¦¬í¬íŠ¸
        print("\nğŸ“Š 3-í´ë˜ìŠ¤ ëª¨ë¸ í‰ê°€ ê²°ê³¼:")
        print(f"   ì „ì²´ ì •í™•ë„: {accuracy:.3f}")
        
        print("\nğŸ“ˆ í´ë˜ìŠ¤ë³„ ì„±ëŠ¥:")
        report = classification_report(y, y_pred, 
                                      target_names=['None (0)', 'Long (1)', 'Short (2)'],
                                      output_dict=True)
        
        for class_name in ['None (0)', 'Long (1)', 'Short (2)']:
            if class_name in report:
                metrics = report[class_name]
                print(f"   {class_name}:")
                print(f"      - Precision: {metrics['precision']:.3f}")
                print(f"      - Recall: {metrics['recall']:.3f}")
                print(f"      - F1-Score: {metrics['f1-score']:.3f}")
        
        print("\nğŸ¯ í˜¼ë™ í–‰ë ¬:")
        print("       ì˜ˆì¸¡ â†’")
        print("ì‹¤ì œâ†“  None  Long  Short")
        labels = ['None', 'Long', 'Short']
        for i, label in enumerate(labels):
            print(f"{label:5} {cm[i][0]:5} {cm[i][1]:5} {cm[i][2]:5}")
        
        # ì¶”ì„¸ ì „í™˜ ê°ì§€ ì„±ëŠ¥ (Long + Short)
        signal_precision = (report.get('Long (1)', {}).get('precision', 0) + 
                          report.get('Short (2)', {}).get('precision', 0)) / 2
        signal_recall = (report.get('Long (1)', {}).get('recall', 0) + 
                       report.get('Short (2)', {}).get('recall', 0)) / 2
        
        print(f"\nğŸ” ì¶”ì„¸ ì „í™˜ ê°ì§€ ì„±ëŠ¥:")
        print(f"   - í‰ê·  Precision: {signal_precision:.3f}")
        print(f"   - í‰ê·  Recall: {signal_recall:.3f}")
        
        return accuracy
    
    def _update_progress_callback(self, message: str):
        """ì§„í–‰ë¥  ì½œë°± ì—…ë°ì´íŠ¸"""
        if self.training_status.get("progress_callback"):
            try:
                self.training_status["progress_callback"](message)
            except:
                pass

class TrainingProgressCallback(tf.keras.callbacks.Callback):
    """í•™ìŠµ ì§„í–‰ë¥  ëª¨ë‹ˆí„°ë§ ì½œë°±"""
    
    def __init__(self, trainer: ModelTrainer):
        super().__init__()
        self.trainer = trainer
    
    def on_epoch_begin(self, epoch, logs=None):
        if not self.trainer.is_training:
            self.model.stop_training = True
            return
            
        self.trainer.training_status["current_epoch"] = epoch + 1
        self.trainer._update_progress_callback(f"ì—í­ {epoch + 1}/{self.trainer.training_status['total_epochs']}")
    
    def on_batch_end(self, batch, logs=None):
        if not self.trainer.is_training:
            self.model.stop_training = True
            return
            
        self.trainer.training_status["current_batch"] = batch + 1
        
        # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        if logs:
            metrics = self.trainer.training_status["metrics"]
            metrics["loss"] = logs.get("loss", 0)
            metrics["accuracy"] = logs.get("accuracy", 0)
            metrics["val_loss"] = logs.get("val_loss", 0)
            metrics["val_accuracy"] = logs.get("val_accuracy", 0)
    
    def on_epoch_end(self, epoch, logs=None):
        if logs:
            metrics = self.trainer.training_status["metrics"] 
            metrics["loss"] = logs.get("loss", 0)
            metrics["accuracy"] = logs.get("accuracy", 0)
            metrics["val_loss"] = logs.get("val_loss", 0)
            metrics["val_accuracy"] = logs.get("val_accuracy", 0)
            
            print(f"ì—í­ {epoch + 1}: ì†ì‹¤={metrics['loss']:.4f}, ì •í™•ë„={metrics['accuracy']:.3f}")

# ============================================================================
# ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸
# ============================================================================

if __name__ == "__main__":
    print("ğŸš€ ModelTrainer 3-í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # í•™ìŠµê¸° ìƒì„±
    trainer = ModelTrainer("BTCUSDT")
    
    # ì„ íƒëœ ì§€í‘œ (MACD ì œì™¸)
    selected_indicators = {
        "sma": True,
        "ema": True,
        "stoch": True,
        "williams": True,
        "mfi": True,
        "vwap": True,
        "volatility": True,
        "pivot": True,
        "zscore": True
    }
    
    # í•™ìŠµ íŒŒë¼ë¯¸í„°
    training_params = {
        "training_days": 1825,  # 1ë…„ ë°ì´í„°
        "epochs": 100,
        "batch_size": 32,
        "learning_rate": 0.001,
        "sequence_length": 60,
        "validation_split": 20,
        "interval": "15"
    }
    
    # ì§„í–‰ë¥  ì½œë°± í•¨ìˆ˜
    def progress_callback(message):
        print(f"ğŸ“¢ {message}")
    
    # í•™ìŠµ ì‹œì‘
    success = trainer.start_training(selected_indicators, training_params, progress_callback)
    
    if success:
        print("âœ… 3-í´ë˜ìŠ¤ í•™ìŠµì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("   - í´ë˜ìŠ¤ 0: None (ì¶”ì„¸ ì „í™˜ ì•„ë‹˜)")
        print("   - í´ë˜ìŠ¤ 1: Long (ìƒìŠ¹ ì „í™˜)")
        print("   - í´ë˜ìŠ¤ 2: Short (í•˜ë½ ì „í™˜)")
        
        # ìƒíƒœ ëª¨ë‹ˆí„°ë§ (ì˜ˆì‹œ)
        import time
        for _ in range(3):
            time.sleep(5)
            status = trainer.get_training_status()
            if status['status'] == 'running':
                print(f"   ì§„í–‰ì¤‘: {status['current_epoch']}/{status['total_epochs']} ì—í­")
    else:
        print("âŒ í•™ìŠµ ì‹œì‘ ì‹¤íŒ¨")
    
    print("\nâœ… ModelTrainer 3-í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")